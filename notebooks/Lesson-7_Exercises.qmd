---
title: "Tema 7: PEC"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
---

# Introducción

En este tema hemos estudiado cómo obtener muestreas "identicamente distribuidas" (¡pero no necesariamente independientes!) de **cualquier distribución de probabilidad** gracias a la familia de algoritmos **Markov chain Monte Carlo** (MCMC).

Además, hemos aprendido acerca de la **dependencia serial** en las cadenas de Markov, cómo diagnosticarla, y su efecto en el **tamaño muestral efectivo de Monte Carlo**.

Estos ejercicios ponen en práctica estos conceptos con modelos de las lecturas, para afianzar estos conceptos.
En el [Ejercicio 1](#ejercicio-1) nos basaremos en el ejemplo del muestreador de Gibbs de @hoff2009a [pp. 98-103] para demostrar la lógica de ese algoritmo, así como las propiedades de una cadenas de Markov generada mediante el método de MCMC.

En el [Ejercicio 2](#ejercicio-2) tomaremos contacto con el software de análisis Bayesiano de datos [Stan](https://mc-stan.org/), utilizando un ejemplo del [texto de ampliación](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34].
Te recomiendo por tanto:

-   Realizar el [Ejercicio 1](#ejercicio-1) en primer lugar.

-   Leer a continuación el epígrafe 1.13 (A Metropolis Example) del [texto de ampliación](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34].

-   Por último, realizar el [Ejercicio 2](#ejercicio-2).

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)
library(scales)
library(rstan) # Nuevo paquete para el ejercicio 2 (añadir al entorno!)

# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto <- PALETA[1]      # Color por defecto
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica

# Redondea los números reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)

# Inicializa la semilla aleatoria:
set.seed(20250408)
```

Inicializamos el entorno como es habitual.
Al igual que en el ejercicio anterior, en este caso **también inicializamos la semilla aleatoria** para asegurar la **reproducibilidad**.

# Ejercicio 1: Cadena de Markov mediante muestreo de Gibbs {#ejercicio-1}

## Distribuciones condicionales

En la primera de las lecturas [@hoff2009a] hemos visto cómo muestrear de distribuciones condicionales.
Vamos a utilizar el ejemplo del epígrafe 6.6 en este ejercicio (pp. 98-103) para demostrar el "muestreo de Gibbs", las propiedades de las cadenas de Markov, y la convergencia.

Recuerda que la distribución que viene definida por[^1]

[^1]: Si te estás preguntando de dónde sale una distribución así, piensa que puede tratarse de una variable en la que hay tres grupos o "clases latentes", cada uno distribuido normalmente pero con medias diferentes; a modo de ejemplo: Usando el ejercicio sobre "velocidad de lectura" en temas anteriores, podríamos tener estudiantes pertenecientes a un grupo de "desarrollo típico" y otros dos grupos con diferentes trastornos de aprendizaje, cada uno teniendo un parámetro distinto para el valor promedio en velocidad de lectura, sin que conozcamos a priori a qué grupo pertenece cada estudiante.

$$
\begin{split}
  {Pr(δ = 1), Pr(δ = 2), Pr(δ = 3)} = (.45, .10, .45) \\
  p(θ|δ) = N(θ, μ_δ, σ_δ); \quad (μ_1, μ_2, μ_3) = (−3, 0, 3); \quad σ_1^2 = σ_2^2 = σ_3^2 = 1/3
\end{split}
$$

Podemos obtener la aproximación discreta a la distribución de $θ$, como hemos hecho en temas anteriores, para usarla como referencia:

```{r distribucion-discreta}
PREC       <- 1e-3             # Precisión para la aproximación discreta
PROB_DELTA <- c(.45, .10, .45) # Probabilidades de los tres grupos
MEDIAS     <- c(-3, 0, 3)      # Medias de los tres grupos en función de "delta"
VAR        <- 1/3              # Varianza de los tres grupos

sd      <- sqrt(VAR) # Desviación estándar de cada grupo
n_desv  <- 5 # Número de "desviaciones estándar" para calcular los límites
lim_inf <- floor(  min(MEDIAS) - n_desv * sd) # Límites para aproximación
lim_sup <- ceiling(max(MEDIAS) + n_desv * sd) #   discreta (inferior y superior)

# Aproximación discreta:
densidad <- tibble(
  theta    = seq(from = lim_inf, to = lim_sup, by = PREC),
  densidad = theta |> dnorm(mean = MEDIAS[1], sd = sd) * PROB_DELTA[1] +
             theta |> dnorm(mean = MEDIAS[2], sd = sd) * PROB_DELTA[2] +
             theta |> dnorm(mean = MEDIAS[3], sd = sd) * PROB_DELTA[3]
)

# Gráfica de la aproximación discreta:
aprox_discreta_plot <- densidad |>
  ggplot(mapping = aes(x = theta, y = densidad)) +
  geom_line(colour = color_defecto) +
  labs(
    title = "Distribución de θ",
    x = "θ",
    y = "p(θ)",
  )

aprox_discreta_plot
```

Tal y como la lectura indica, en esta distribución sería muy sencillo obtener una muestra de Monte Carlo i.i.d. Así que ten en cuenta que este ejercicio tiene un **propósito ilustrativo** sobre las **propiedades del muestreador de Gibbs**, y la aproximación de Monte Carlo que resulta de la cadena de Markov generada por este algoritmo.

### Pregunta 1

-   Dado un valor de $δ$, escibe a continuación una función que devuelva una única muestra aleatoria de $θ$ (i.e., una muestra de tamaño 1) de la distribución $p(θ|δ)$. Utiliza el prototipo de la función que se da a continuación, y los objetos globales definidos en el "chunk" de código anterior sin necesidad de definirlos de nuevo (`PROB_DELTA`, `MEDIAS`, `VAR`, o `sd`, según los necesites).

::: {#respuesta-1 .callout-note}
```{r muestrear-theta}
# Argumento `delta`: Valor entero de δ para muestrear $p(θ|δ)$
muestrear_theta <- function(delta) {
  # Verificar que delta sea un valor válido (entre 1 y el número de componentes)
  # He hecho la función genérica aunque podría haber utilizado simplemente c(1, 2, 3)
  if (!delta %in% seq_along(MEDIAS)) {
    stop(paste("El valor de delta debe estar entre 1 y", length(MEDIAS)))
  }
  
  # Obtener la media correspondiente al valor de delta
  media <- MEDIAS[delta]
  
  # Generar una muestra aleatoria de la distribución normal
  # con la media correspondiente y la desviación estándar definida
  rnorm(n = 1, mean = media, sd = sd)
}
```
:::

### Pregunta 2

-   Dado un valor de $θ$, escibe a continuación una función que devuelva una única muestra aleatoria de $δ$ (i.e., una muestra de tamaño 1) de la distribución $p(δ|θ)$, tal y como se indica en la ecuación de la p. 100 de @hoff2009a. Utiliza el prototipo de la función que se da a continuación, y los objetos globales definidos en el "chunk" de código anterior sin necesidad de definirlos de nuevo (`PROB_DELTA`, `MEDIAS`, `VAR`, o `sd`, según los necesites).

::: {#respuesta-2 .callout-note}
la distribución condicional p(δ|θ) viene dada por la fórmula:  
  
$$\text{Pr}(\delta = d|\theta) = \frac{\text{Pr}(\delta = d) \times \text{dnorm}(\theta, \mu_d, \sigma_d)}{\sum_{i=1}^{3}\text{Pr}(\delta = i) \times \text{dnorm}(\theta, \mu_i, \sigma_i)}$$
  
Para implementar esta función, necesitamos:  
  
1. Calcular las probabilidades condicionales para cada valor posible de δ (1, 2, 3).  
2. Normalizar estas probabilidades para que sumen 1.  
3. Realizar un muestreo aleatorio basado en estas probabilidades.  
  
```{r muestrear-delta}
# Argumento `theta`: Valor real de θ para muestrear $p(δ|θ)$
muestrear_delta <- function(theta) {
  # Calcular las probabilidades no normalizadas para cada valor de delta
  prob_no_normalizada <- numeric(length(MEDIAS))
  
  for (d in seq_along(MEDIAS)) {
    # Pr(δ = d) × dnorm(θ, μ_d, σ_d)
    prob_no_normalizada[d] <- PROB_DELTA[d] * dnorm(theta, mean = MEDIAS[d], sd = sd)
  }
  
  # Normalizar las probabilidades para que sumen 1
  prob_normalizada <- prob_no_normalizada / sum(prob_no_normalizada)
  
  # Muestrear un valor de delta basado en estas probabilidades
  sample(seq_along(MEDIAS), size = 1, prob = prob_normalizada)
}
```
:::

## Muestreador de Gibbs

A continuación tienes una función que realiza una iteración del muestreador de Gibbs utilizando las dos funciones que acabas de escribir, devolviendo una muestra de tamaño 1 de la distribución conjunta $p(θ, δ)$.
Es decir, dado el estado actual de la cadena de Markov, la función devuelve el siguiente estado.

```{r definir-iteracion-Gibbs}
itera_Gibbs <- function(theta, delta) {
  
  # Muestra de theta:
  theta <- muestrear_theta(delta) # Observa que el valor "actual" de theta en
                                  #   realidad no se usa en esta función, pero
                                  #   lo usamos como argumento para definir el
                                  #   "estado actual completo" de la cadena.
  # Muestra de delta:
  delta <- muestrear_delta(theta)
  
  # Devuelve el nuevo estado de la cadena de Markov:
  tibble(theta = theta, delta = delta) # Usamos el tipo "tibble" para devolver a
                                       #   la vez un número real y un entero.
}
```

Ahora vamos a definir un objeto para "almacenar" los estados de la cadena de Markov.
Aunque podríamos ir "concatenando" las filas resultantes de cada estado, es mucho más eficiente (por cómo R maneja la memoria) definir un objeto de tamaño conocido e ir "rellenándolo" con los estados de la cadena.
Para ello, vamos a necesitar el número de iteraciones de la cadena, que fijaremos en 1,000, como en el ejemplo del libro.

```{r definir-cadena-Gibbs}
N_GIBBS <- 1000 # Número de iteraciones de la cadena de Markov

cadena_Gibbs <- tibble( # Objeto para almacenar los estados de la cadena
  theta = numeric(N_GIBBS),
  delta = integer(N_GIBBS)
)
```

Con los objetos anteriores, ya tenemos casi todo lo necesario para realizar el muestreo de Gibbs.
Solamente falta el estado inicial de la cadena.

### Pregunta 3

-   Define un objeto `estado_cadena` de tipo "tibble" para que contenga un estado inicial de la cadena de Markov que tenga una alta probabilidad de encontrarse en la distribución estacionaria. Para ello, selecciona un valor próximo a uno de los tres modos de la distribución de $θ$ y un valor adecuado de $δ$, justificando la elección de ambos.

::: {#respuesta-3 .callout-note}
```{r crear-estado-cadena}
# Elijo δ = 3 (con probabilidad 0.45) y θ = 2.9 (cercano a la media correspondiente)
estado_cadena <- tibble(
  theta = 2.9,    # Valor cercano al modo en θ = 3
  delta = 3     # Valor correspondiente a ese modo
)
```
  
Para definir un estado inicial adecuado para la cadena de Markov, necesitamos elegir valores de θ y δ que tengan una alta probabilidad de encontrarse en la distribución estacionaria.  
  
Analizando la distribución conjunta p(θ, δ):  
  
1. Sabemos que la distribución marginal de δ es:  
- Pr(δ = 1) = 0.45  
- Pr(δ = 2) = 0.10  
- Pr(δ = 3) = 0.45  
  
2. La distribución condicional de θ dado δ es:  
- p(θ|δ = 1) = N(-3, 1/3)  
- p(θ|δ = 2) = N(0, 1/3)  
- p(θ|δ = 3) = N(3, 1/3)  
  
3. Por lo tanto, la distribución de θ tiene tres modos, ubicados en -3, 0 y 3.  
  
Los valores δ con alta probabilidad marginal son 1 y 3. Cualquiera de los dos hubiera sido válido. Escojo 3, por tanto el valor θ ha de ser cercano a la media de la distribución condicional correspondiente, que es 3 para δ = 3, por lo que escojo 2.9 (hubiera escogido 3 directamente, pero como dices "valor próximo a uno de los tres modos", prefiero interpretar literalmente). 
  
El orden seguido también ha sido al revés (he seleccionado primero δ y después θ), espero que no importe.  
:::

### Pregunta 4

-   Escribe el código necesario para iterar la cadena de Markov, comenzando en el valor definido anteriormente de `estado_cadena`, y guardando los estados en el objeto `cadena_Gibbs`.

::: {#respuesta-4 .callout-note}
```{r iterar-cadena-Markov}
# Iniciar el primer estado de la cadena con  estado_cadena
cadena_Gibbs[1, ] <- estado_cadena

# Iterar para generar los estados restantes
for (i in 2:N_GIBBS) {
  # Obtenemos el estado anterior
  theta_anterior <- cadena_Gibbs$theta[i-1]
  delta_anterior <- cadena_Gibbs$delta[i-1]
  
  # Generar el nuevo estado usando la función itera_Gibbs
  nuevo_estado <- itera_Gibbs(theta_anterior, delta_anterior)
  
  # Almacenar el nuevo estado en la cadena
  cadena_Gibbs[i, ] <- nuevo_estado
}
```

:::

### Pregunta 5

-   Representa la densidad de la distribución de $θ$ obtenida a partir de la cadena de Markov junto con la aproximación discreta que obtuvimos antes. Explica qué observas en el resultado.

::: {#respuesta-5 .callout-note}
```{r representacion-grafica}
# Crear gráfico comparativo con dos curvas de densidad
comparacion_densidad_plot <- ggplot() +
  # Curva de densidad empírica de la cadena MCMC
  geom_density(data = cadena_Gibbs, 
               mapping = aes(x = theta, color = "MCMC (Gibbs)")) +
  # Curva de densidad teórica
  geom_line(data = densidad, 
            mapping = aes(x = theta, y = densidad, color = "Teórica")) +
  # Configuración de color y la leyenda
  scale_color_discrete(name = "Distribución") +
  labs(
    title = "Comparación de densidades: empírica vs. teórica",
    x = "θ",
    y = "Densidad"
  ) +
  theme(legend.position = "bottom")

# Mostrar el gráfico
comparacion_densidad_plot
```
  
Ambas distribuciones muestran claramente una estructura trimodal, con ubicación de los picos muy similar en ambas distribuciones (-3, 0 y 3), que corresponde a las 3 componentes de la mezcla. Sin embargo se observan diferencias notables en la densidad empírica con el muestreador de Gibbs.  
  
- **Modo en θ = -3**: La densidad empírica (MCMC) muestra un pico más bajo que la teórica, cercano a 0.1 vs la densidad teórica en esa zona que supera el 0.3, lo que sugiere que esta región está muy subrepresentada en la cadena de Markov.  
- **Modo en θ = 0**: La densidad empírica muestra un pico más alto que la teórica, indicando una sobrerrepresentación de esta región.  
- **Modo en θ = 3**: Ambas distribuciones tienen alturas similares en este modo, sugiriendo una mejor aproximación en esta región.  

##### Posibles explicaciones:
1. **Tamaño muestral efectivo**: Debido a la correlación entre muestras consecutivas, el tamaño muestral efectivo es menor que las 1000 iteraciones realizadas, lo que limita la precisión de la aproximación y resalta todas las limitaciones del muestreador de Gibbs.  
2. **Correlación serial**: El muestreador de Gibbs genera muestras correlacionadas, lo que puede provocar que ciertas regiones del espacio de estados se exploren más o menos de lo esperado en un muestreo i.i.d.  
3. **Efecto del estado inicial**: Al iniciar la cadena cerca del modo θ = 3, en uno de los límites, es posible que la cadena no haya tenido suficientes iteraciones para explorar adecuadamente las otras regiones, especialmente la más alejada de θ = -3.
4. **Transiciones entre modos**: En relación a lo anterior se ha de tener en cuenta también que el muestreador de Gibbs puede tener dificultades para moverse entre modos distantes, especialmente si la probabilidad de la componente intermedia (δ = 2) es baja (0.10 en este caso).  
:::

## Diagnósticos

### Pregunta 6

-   Usando las funciones indicadas en la p. 103 de @hoff2009a, representa la autocorrelación serial de los valores de $θ$ en la cadena y calcula el tamaño muestral efectivo de Monte Carlo.

*(NOTA: No olvides añadir el paquete `{coda}` en el entorno con el botón "renv" -\> "Snapshot Library...".)*

::: {#respuesta-6 .callout-note}
Las principales funciones mencionadas para el análisis de cadenas de Markov son:

- *acf*: Función de R base que calcula la función de autocorrelación para una serie temporal. La fórmula para la autocorrelación de lag-t es:  
$$\text{acf}t(\phi) = \frac{\frac{1}{n-t}\sum{s=1}^{n-t}(\phi_s - \bar{\phi})(\phi_{s+t} - \bar{\phi})}{\frac{1}{n}\sum_{s=1}^{n}(\phi_s - \bar{\phi})^2}$$

- *effectiveSize*: Función del paquete coda que estima el tamaño muestral efectivo para una cadena MCMC. Calcula $S_{\text{eff}}$ tal que:  
$$\text{Var}{\text{MCMC}}[\bar{\phi}] = \frac{\text{Var}[\phi]}{S{\text{eff}}}$$

donde $S_{\text{eff}}$ representa el número de muestras independientes que darían la misma precisión que nuestras muestras MCMC correlacionadas.  

```{r autocorrelacion-serial}
# Cargar el paquete coda
library(coda)

# Convertir la cadena de valores theta a un objeto mcmc
theta_mcmc <- as.mcmc(cadena_Gibbs$theta)

# Calcular la autocorrelación usando acf
acf_result <- acf(cadena_Gibbs$theta, lag.max = 20, plot = FALSE)

# Crear un gráfico de autocorrelación
acf_plot <- ggplot() +
  geom_line(data = tibble(
    lag = acf_result$lag,
    acf = acf_result$acf
  ), 
  aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = color_defecto) +
  labs(
    title = "Autocorrelación de θ en la cadena de Markov",
    x = "Lag",
    y = "Autocorrelación"
  )

# Mostrar el gráfico de autocorrelación
acf_plot

# Calcular el tamaño muestral efectivo
ess <- effectiveSize(theta_mcmc)

# Mostrar el resultado
cat("Tamaño muestral efectivo de Monte Carlo para θ:", round(ess, 2), "\n")
cat("Proporción del tamaño original:", round(ess/N_GIBBS, 4), "\n")
```
  
El gráfico obtenido muestra un patrón preocupante para la cadena de Markov ya que tiene una autocorrelación extremadamente alta, manteniéndose por encima de 0.75 incluso para un lag=20. Disminuye muy lentamente con una pendiente de línea muy suave, lo que indica que los valores de θ en la cadena permanecen altamente correlacionados incluso cuando están separados por muchos pasos.  
  
Para las 1000 muestras correlacionadas que aportamos se aport la misma precisión estadística que sólo `{r} round(ess, 0)` muestras independientes. La eficiencia es extremadamente baja, sólo el `{r} round(ess/N_GIBBS, 4)`% de lo que sería un muestreo independiente.  
  
Se confirma lo que menciona @hoff2009a sobre la *stickiness* (tendencia a permanecer en la misma región del espacio de parámetros durante muchos pasos), el movimiento lento entre regiones representadas por los tres valores de δ y por tanto la exploración ineficiente del espacio de parámetros.  
:::

### Pregunta 7

-   Define un objeto `cadena_Gibbs2`, de igual manera que definiste `cadena_Gibbs`, y repite la pregunta 3, pero eligiendo un estado inicial en otro modo distinto. Después, genera una nueva cadena de Markov, almacenando sus estados en `cadena_Gibbs2` como en el ejercicio 4, y repite las representaciones y cálculos de los ejercicios 5 y 6.

::: {#respuesta-7 .callout-note}
```{r nueva-cadena-Markov}
cadena_Gibbs2 <- tibble( # Objeto para almacenar los estados de la cadena
  theta = numeric(N_GIBBS),
  delta = integer(N_GIBBS)
)

# Elijo δ = 2 (con probabilidad 0.10) y θ = -0.1 (cercano a la media correspondiente), ya que entiendo que escoger δ = 1 dará resultados similares a la cadena anterior pero alrededor de θ = -3
estado_cadena2 <- tibble(
  theta = -0.1,    # Valor cercano al modo en θ = 3
  delta = 2     # Valor correspondiente a ese modo
)

# Iniciar el primer estado de la cadena con  estado_cadena
cadena_Gibbs2[1, ] <- estado_cadena2

# Iterar para generar los estados restantes
for (i in 2:N_GIBBS) {
  # Obtenemos el estado anterior
  theta_anterior2 <- cadena_Gibbs2$theta[i-1]
  delta_anterior2 <- cadena_Gibbs2$delta[i-1]
  
  # Generar el nuevo estado usando la función itera_Gibbs
  nuevo_estado2 <- itera_Gibbs(theta_anterior2, delta_anterior2)
  
  # Almacenar el nuevo estado en la cadena
  cadena_Gibbs2[i, ] <- nuevo_estado2
}

# Crear gráfico comparativo con dos curvas de densidad
comparacion_densidad_plot2 <- ggplot() +
  # Curva de densidad empírica de la cadena MCMC
  geom_density(data = cadena_Gibbs, 
               mapping = aes(x = theta, color = "MCMC (Gibbs) δ=3")) +
  # Curva de densidad teórica
  geom_line(data = densidad, 
            mapping = aes(x = theta, y = densidad, color = "Teórica")) +
  # Curva de densidad empírica de la cadena MCMC2
  geom_density(data = cadena_Gibbs2, 
               mapping = aes(x = theta, color = "MCMC (Gibbs) δ=2")) +
  # Configuración de color y la leyenda
  scale_color_discrete(name = "Distribución") +
  labs(
    title = "Comparación de densidades: empírica δ2 vs. empírica δ=3  vs. teórica",
    x = "θ",
    y = "Densidad"
  ) +
  theme(legend.position = "bottom")

# Mostrar el gráfico
comparacion_densidad_plot2


# Convertir la cadena de valores theta a un objeto mcmc
theta_mcmc2 <- as.mcmc(cadena_Gibbs2$theta)

# Calcular la autocorrelación usando acf
acf_result2 <- acf(cadena_Gibbs2$theta, lag.max = 20, plot = FALSE)

# Crear un gráfico de autocorrelación
acf_plot2 <- ggplot() +
  geom_line(data = tibble(
    lag = acf_result2$lag,
    acf = acf_result2$acf
  ), 
  aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = color_defecto) +
  labs(
    title = "Autocorrelación de θ en la cadena de Markov",
    x = "Lag",
    y = "Autocorrelación"
  )

# Mostrar el gráfico de autocorrelación
acf_plot2

# Calcular el tamaño muestral efectivo
ess2 <- effectiveSize(theta_mcmc2)

# Mostrar el resultado
cat("Tamaño muestral efectivo de Monte Carlo para θ:", round(ess2, 2), "\n")
cat("Proporción del tamaño original:", round(ess2/N_GIBBS, 4), "\n")
```
Las distribuciones empíricas muestran que la cadena iniciada con d2 (δ = 1 es un error) se queda "atrapada" en θ = -3, sobreestimando mucho esa región y no explora nada θ = 3, reforzando la idea de que es mejor que la cadena de Markov comience en una región de alta densidad de probabilidad.

Sin embargo, contrariamente a lo que esperaba, se muestra una autocorrelación y comparación del tamaño muestral efectivo mejorados para esta segunda cadena. La autocorrelación tiene un decaimiento mucho más rápido que la primera cadena, lleegando a 0.1 en lag=20 y un tamaño muestral efectivo aproximadamente 17 veces mayor que la primera (ESS=`{r} round(ess2, 0)`, proporción=`{r} round(ess2/N_GIBBS, 4)`%).  
  
Esto puede suceder porque las métricas estándar de autocorrelación y tamaño muestral efectivo no capturan bien el problema de la multimodalidad y la falta de exploración entre modos distantes. Es decir, no detectan que la cadena se "atrapa" en una región, simplemente valoran que dentro de esa region los valores consecutivos de θ muestran menor correlación entre sí y la cadena se mueve eficientemente simulando un comportamiento relativamente "independiente".  
  
De todas formas los valores de estos dos parámetros siguen siendo bajos.  
:::

### Pregunta 8

**ATENCIÓN: El siguiente ejercicio NO está basado en la lectura; presta especial atención.**

-   Consulta la ayuda de la función `gelman.diag()` del paquete `{coda}`. Después, completa el siguiente chunk para calcular el estadístico $R$ (diagnóstico de Gelman-Rubin) para los valores de $θ$ a partir de las dos cadena de Markov que acabas de generar e interprétalo.

::: {#respuesta-8 .callout-note}
```{r calcular-diagnostico-GR}
# Crear una lista con las dos cadenas
theta_Gibbs <- list(
  theta_Gibbs_1 = cadena_Gibbs  |> pull(theta) |> as.mcmc(),
  theta_Gibbs_2 = cadena_Gibbs2 |> pull(theta) |> as.mcmc()
)

# Convertir las dos cadenas en un objeto mcmc.list
theta_Gibbs_mcmc <- mcmc.list(theta_Gibbs)

# Calcular el diagnóstico de Gelman-Rubin
diagnostico_GR <- gelman.diag(theta_Gibbs_mcmc)

# Visualizar el diagnóstico
gelman.plot(theta_Gibbs_mcmc)

# Mostrar el resultado
print(diagnostico_GR)
```
  
El estadístico $R$ compara la varianza entre cadenas con la varianza dentro de cada cadena para determinar si las cadenas han convergido a la misma distribución estacionaria.  
  
Generalmente se aceptan valores de $R < 1.1$ para aceptar la inferencia de que las cadenas han convergido a la misma distribución estacionaria, mientras que contra más se alejen de 1 se rechaza esa hipótesis. La propia función establece en su descripción un límite superior cercano a 1 para aceptar convergencia.  
  
En este caso el valor de $R=1.77$ está sustancialmente por encima del umbral con un límite superior en el intérvalo de confianza que indica gran incertidumbre, lo que sugiere problemas importantes de convergencia.  

El gráfico de *shrink factor* debería ir disminuyendo y estabilizándose cerca de 1 a medida que aumentan las iteraciones, sin embargo se mantiene elevado a lo largo de toda la cadena; la mediana como el percentil 97.5 se mantienen muy por encima de 1, lo que indica que incluso después de 1000 iteraciones, las cadenas siguen explorando diferentes regiones del espacio de parámetros.  
  
Se concluye tal y como se podía intuir que las dos cadenas no convergen a la misma distribución estacionaria incluso después de 1000 iteraciones. Cada cadena está "atrapada" en una región diferente del espacio de parámetros (una alrededor de θ = -3 y otra alrededor de θ = 3).  
:::

### Pregunta 9

-   De forma similar a como se ha hecho en la pregunta 7, obten dos cadenas de Markov de la distribución posterior conjunta de $p(θ, δ)$, pero con una longitud de 100,000 (ten paciencia, puede tardar un rato en hacer las iteraciones). Repite con estas dos nuevas cadenas los ejercicios 5, 6 y 8.

*(NOTA: Responde en el chunk de R proporcionado; la opción `#| cache: true` te ahorrará mucho tiempo de espera al renderizar el notebook después de hacerlo por primera vez.)*

::: {#respuesta-9 .callout-note}
```{r muestrear-Gibbs-100000}
#| cache: true # Guarda los resultados para no tener que ejecutar el "chunk"
               #   cada vez que se renderiza el notebook.

N_GIBBS_100000 <- 100000 # Número de iteraciones de la cadena de Markov

cadena_Gibbs3 <- tibble( # Objeto para almacenar los estados de la cadena
  theta = numeric(N_GIBBS_100000),
  delta = integer(N_GIBBS_100000)
)

cadena_Gibbs4 <- tibble( # Objeto para almacenar los estados de la cadena
  theta = numeric(N_GIBBS_100000),
  delta = integer(N_GIBBS_100000)
)

# Crear los dos estados de cadena con δ = 3 y 2 y θ = 2.9 y -0.1
estado_cadena3 <- tibble(
  theta = 2.9,    # Valor cercano al modo en θ = 3
  delta = 3     # Valor correspondiente a ese modo
)

estado_cadena4 <- tibble(
  theta = -0.1,    # Valor cercano al modo en θ = 0
  delta = 2     # Valor correspondiente a ese modo
)

# Iniciar el primer estado de la cadena con los estados de cadena
cadena_Gibbs3[1, ] <- estado_cadena3
cadena_Gibbs4[1, ] <- estado_cadena4

# Iterar para generar los estados restantes
for (i in 2:N_GIBBS_100000) {
  # Obtenemos el estado anterior
  theta_anterior3 <- cadena_Gibbs3$theta[i-1]
  delta_anterior3 <- cadena_Gibbs3$delta[i-1]
  theta_anterior4 <- cadena_Gibbs4$theta[i-1]
  delta_anterior4 <- cadena_Gibbs4$delta[i-1]
  
  # Generar el nuevo estado usando la función itera_Gibbs
  nuevo_estado3 <- itera_Gibbs(theta_anterior3, delta_anterior3)
  nuevo_estado4 <- itera_Gibbs(theta_anterior4, delta_anterior4)
  
  # Almacenar el nuevo estado en la cadena
  cadena_Gibbs3[i, ] <- nuevo_estado3
  cadena_Gibbs4[i, ] <- nuevo_estado4
}

# Crear gráfico comparativo con dos curvas de densidad
comparacion_densidad_plot3 <- ggplot() +
  # Curva de densidad empírica de la cadena MCMC
  geom_density(data = cadena_Gibbs3, 
               mapping = aes(x = theta, color = "MCMC (Gibbs) δ=3")) +
  # Curva de densidad teórica
  geom_line(data = densidad, 
            mapping = aes(x = theta, y = densidad, color = "Teórica")) +
  # Curva de densidad empírica de la cadena MCMC2
  geom_density(data = cadena_Gibbs4, 
               mapping = aes(x = theta, color = "MCMC (Gibbs) δ=2")) +
  # Configuración de color y la leyenda
  scale_color_discrete(name = "Distribución") +
  labs(
    title = "Densidades itera. 100000: empírica δ2 vs. empírica δ=3 vs. teórica",
    x = "θ",
    y = "Densidad"
  ) +
  theme(legend.position = "bottom")

# Mostrar el gráfico
comparacion_densidad_plot3

# Convertir la cadena de valores theta a un objeto mcmc
theta_mcmc3 <- as.mcmc(cadena_Gibbs3$theta)
theta_mcmc4 <- as.mcmc(cadena_Gibbs4$theta)

# Calcular la autocorrelación usando acf
acf_result3 <- acf(cadena_Gibbs3$theta, lag.max = 20, plot = FALSE)
acf_result4 <- acf(cadena_Gibbs4$theta, lag.max = 20, plot = FALSE)

# Crear un gráfico de autocorrelación
acf_plot3 <- ggplot() +
  geom_line(data = tibble(
    lag = acf_result3$lag,
    acf = acf_result3$acf
  ), 
  aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = color_defecto) +
  labs(
    title = "Autocorrelación de θ en la cadena de Markov (δ=3)",
    x = "Lag",
    y = "Autocorrelación"
  )
acf_plot4 <- ggplot() +
  geom_line(data = tibble(
    lag = acf_result4$lag,
    acf = acf_result4$acf
  ), 
  aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = color_defecto) +
  labs(
    title = "Autocorrelación de θ en la cadena de Markov (δ=2)",
    x = "Lag",
    y = "Autocorrelación"
  )

# Mostrar el gráfico de autocorrelación
acf_plot3
acf_plot4

# Calcular el tamaño muestral efectivo
ess3 <- effectiveSize(theta_mcmc3)
ess4 <- effectiveSize(theta_mcmc4)

# Mostrar el resultado
cat("Tamaño muestral efectivo de Monte Carlo para θ con la primera cadena:", round(ess3, 2), "\n")
cat("Tamaño muestral efectivo de Monte Carlo para θ con la segunda cadena:", round(ess4, 2), "\n")
cat("Proporción del tamaño original con la primera cadena:", round(ess3/N_GIBBS_100000, 4), "\n")
cat("Proporción del tamaño original con la segunda cadena:", round(ess4/N_GIBBS_100000, 4), "\n")

# Calcular diagnostico GR
# Crear una lista con las dos cadenas
theta_Gibbs2 <- list(
  theta_Gibbs_3 = cadena_Gibbs3$theta |> as.mcmc(),
  theta_Gibbs_4 = cadena_Gibbs4$theta |> as.mcmc()
)

# Convertir las dos cadenas en un objeto mcmc.list
theta_Gibbs_mcmc2 <- mcmc.list(theta_Gibbs2)

# Calcular el diagnóstico de Gelman-Rubin
diagnostico_GR2 <- gelman.diag(theta_Gibbs_mcmc2)

# Visualizar el diagnóstico
gelman.plot(theta_Gibbs_mcmc2)

# Mostrar el resultado
print(diagnostico_GR2)
```
  
Los gráficos muestran una convergencia adecuada a la distribución teórica para ambas cadenas con 100.000 iteraciones. Representan los tres modos con alturas relativas mucho más cercanas a las proporciones teóricas (0.45, 0.10 y 0.45), haciendo una exploración completa del espacio de parámetros.  
  
Sin embargo la autocorrelación sigue siendo alta incluso después de 20 lags, manteniéndose por encima de 0.9 con un decaimiento muy lento y un comportamiento similar en ambas cadenas.  
  
El tamaño muestral es efectiva en aproximadamente 178-179 para ambas cadenas y una proporción del tamaño original del 0.18%, que significa que a pesar de haber generado 100.000 muestras, la información estadística contenida es equivalente no llega a ser equivalente a unas 180 muestras independientes, por lo que la eficiencia sigue siendo extremadamente baja.  
  
El diagnóstico de Gelman-Rubin muestra que las cadenas han convergido a la misma distribución estacionaria, con una estimación puntual de R de 1.00 y límite sup. IC 1.00.  
  
Para converger a la distribución correcta necesitamos 100 veces más iteraciones que en el caso anterior a costa de un mayor tiempo de mezcla y costo computacional, y de seguir manteniendo una alta correlación, lo que la sigue haciendo altamente ineficiente.  
:::

### Pregunta 10

-   La pregunta 8 demuestra el uso del estadístico de convergencia de Gelman-Rubin para cadenas de Markov, pero hace una serie de supuestos que no siempre se cumplen. En base a la ayuda de `gelman.diag()`, ¿cómo interpretarías los resultados del estadístico $R$ obtenidos en estos casos? ¿Qué crees que ocurriría si lo calculamos con dos (o más) cadenas que convergen "parcialmente" a uno de los modos de la distribución únicamente?

::: {#respuesta-10 .callout-note}
Tal y como se ha comentado para diagnosticar convergencia de cadenas *gelman.diag()* acepta un límite del IC sup cercano a 1. En este caso, con 1.000 iteraciones hemos obtenido un límite para el IC de 5.27, lo que indica falta de convergencia, y una convergencia adecuada con IC sup de 1.00 para las 100.000 iteraciones.  
  
Este estadístico se basa en varios supuestos importantes:  
1. *Estacionariedad*: Las cadenas deben haber alcanzado su distribución estacionaria.  
2. *Ergodismo*: Las cadenas deben poder explicar todo el espacio de parámetros.
3. *Misma distribución objetivo*: Todas las cadenas deben converger a la misma distribución.

Sin embargo el planteamiento tiene sus limitaciones:  
1. *No detecta modos no explorados*: Como hace la comparación entre cadenas y no con la distribución teórica, si todas las cadenas omiten un modo de distribución, R podría ser cercano a 1 a pesar de una exploración incompleta.  
2. *Puede ser engañoso en distribuciones multimodales*: Si por el contrario, tal y como se plantea en el enunciado, cada cadena explora adecuadamente un modo diferente pero no se mueve entre modos (por ejemplo, una atrapada alrededor de θ = -3 y otra alrededor de θ = 3), obtendríamos un valor de R muy por encima de 1, indicando falta de convergencia, que no disminuiría hacia 1 aunque aumentáramos el número de iteraciones, aunque cada cadena muestreara correctamente su región local.  
3. *Sensible al punto inicial*: Sobretodo a menores iteraciones, tal y como se ha visto en este ejemplo, el punto inicial puede tener un impacto significativo en la región explorada por la cadena.  
:::

## Distribución estacionaria

### Pregunta 11

-   Si crees que las cadenas en la pregunta 9 no han convergido satisfactoriamente a la distribución estacionaria, vuelve a ejecutarlas (quizá con mayor longitud) hasta obtener una convergencia sastisfactoria. Si consideras la convergencia de las cadenas satisfactoria (o una vez la consideres satisfactoria), colapsa los estados de ambas cadenas en un solo "data.frame" y obtén la densidad de $θ$ con las muestras de ambas cadenas.

::: {#respuesta-11 .callout-note}
Como se ha justificado previamente las cadenas han convergido satisfactoriamente a la distribución estacionaria así que procedo directamente a colapsarlas.  
  
```{r colapsar-cadenas}
# Colapsar las dos cadenas en un único data.frame
cadenas_combinadas <- bind_rows(
  cadena_Gibbs3 %>% mutate(cadena = "Cadena 1"),
  cadena_Gibbs4 %>% mutate(cadena = "Cadena 2")
)

# Crear un gráfico de densidad con las muestras combinadas
densidad_combinada_plot <- ggplot() +
  # Densidad de las muestras combinadas
  geom_density(data = cadenas_combinadas, 
               mapping = aes(x = theta), 
               color = PALETA[1],
               linewidth = 1) +
  # Densidad teórica para comparación
  geom_line(data = densidad, 
            mapping = aes(x = theta, y = densidad),
            color = PALETA[2],
            linewidth = 1,
            linetype = "dashed") +
  # Etiquetas y título
  labs(
    title = "Densidad de θ combinando ambas cadenas vs. teórica",
    x = "θ",
    y = "Densidad",
    caption = "Línea sólida: densidad empírica combinada | Línea punteada: densidad teórica"
  )

# Mostrar el gráfico
densidad_combinada_plot
```

:::

# Ejercicio 2: Ajuste de un modelo en Stan {#ejercicio-2}

Ahora que tienes una noción de qué es una cadena de Markov y cómo puede utilizarse para aproximar una distribución posterior, vamos a estimar un modelo Bayesiano relativamente complejo.
Hasta ahora hemos demostrado la aproximación a una distribución conocida mediante el método MCMC.
Sin embargo, recuerda que podemos aproximar cualquier distribución posterior gracias al algoritmo Metropolis-Hastings.
Esto incluye aquellas para las que no conocemos su "verosimilitud marginal" o "constante de proporcionalidad" [recuerda la "fórmula de la proporcionalidad en la [lectura del Tema 3](https://agora.uned.es/mod/resource/view.php?id=506207), @puza2015a, pp. 13-18].

Para estimar este modelo, vamos a utilizar el software [Stan](https://mc-stan.org/).
Stan es un software de análisis Bayesiano de datos que utiliza internamente un algoritmo MCMC para realizar la aproximación numérica de la distribución posterior de un modelo.

Verás que Stan obtiene muestras MCMC de manera muy rápida en comparación con el ejemplo que vimos en el Ejercicio 1.
Esto se debe a que "convierte" la especificación de un modelo a "código compilado" en C++ (en lugar de "traducir" el código línea a línea, como hace el intérprete de R).
Pero para ello, es necesario instalar las "herramientas de compilación" de R.
Así que antes de comenzar a usar Stan, asegúrate de tener instalada la versión de RTools correspondiente a tu sistema operativo, siguiendo las [instrucciones en el repositorio de Rstan en GitHub](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#configuring-c-toolchain).
Una vez hayas comprobado que Stan funciona, ejecutando el ejemplo según se indica en la sección [Verifying installation](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#verifying-installation), continúa con el ejercicio.

## Regresión logística

En el [texto de ampliación del tema](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34] puedes ver un ejemplo de ajuste de un modelo de regresión logística Bayesiano, utilizando el paquete [`{mcmc}`](https://cran.r-project.org/package=mcmc) del propio autor.
Asegúrate de familiarizarte con el ejemplo, ya que lo utilizaremos en este ejercicio.

### Pregunta 12

-   Carga el dataset `logit` del paquete `{mcmc}`, explóralo, y explica su contenido.

*(NOTA: No olvides añadir el paquete `{mcmc}` al entorno.)*

::: {#respuesta-12 .callout-note}
:::

### Pregunta 13

-   Utiliza el código proporcionado por el autor para ajustar el modelo lineal general con los datos y especificaciones del propio autor (p. 30) en un marco frecuentista. Comenta brevemente los resultados.

::: {#respuesta-13 .callout-note}
:::

## Especificación en Stan

El [archivo "src/geyer_2011_logistic.stan"](src/geyer_2011_logistic.stan) contiene la sintaxis en Stan equivalente al modelo de regresión logística en @geyer2011 [pp. 31-32].

La sintaxis de R a continuación ejecuta el modelo usando el paquete [`{rstan}`](https://cran.r-project.org/package=rstan).
Consulta la [guía de usuario de Stan](https://mc-stan.org/docs/2_36/stan-users-guide/) para familiarizarte con esta sintaxis.

```{r ajustar-modelo-Stan}
#| cache: true

# Configuración de Stan para mejorar la eficiencia:
options(mc.cores = parallel::detectCores()) # Computación en paralelo
rstan_options(auto_write = TRUE)            # Escribe el modelo compilado

# Datos de entrada al modelo
datos_logit <- list(
  y = logit |> pull(y),
  x = logit |> select(starts_with('x')),
  N = nrow(logit),
  K = ncol(logit) - 1L
)

# Ajustar el modelo
fit_logit_stan <- stan(
  file   = "../src/geyer_2011_logistic.stan",
  iter   = 1000L,
  chains =    4L,
  data   = datos_logit
)
```

### Pregunta 14

-   Fíjate en la sección `data` (líneas 2-7) en el modelo de Stan. En base a esto, explica la estructura del objeto `datos_logit`.

::: {#respuesta-14 .callout-note}
:::

### Pregunta 15

-   Muestra el objeto `fit_logit_stan` y explica el significado del siguiente texto, de acuerdo a los términos que aparecen en las lecturas del tema:

    Inference for Stan model: anon_model.
    4 chains, each with iter=1000; warmup=500; thin=1; post-warmup draws per chain=500, total post-warmup draws=2000.

Explica también qué significan los valores e la columna `se_mean` y cómo se interpretan.

::: {#respuesta-15 .callout-note}
:::

### Pregunta 16

-   Explica cómo se diferencian las especificaciones del algoritmo en Stan anterior de las utilizadas por @geyer2011, en cuanto a número de cadenas, iteraciones, "burn-in", "thinning", y valores iniciales de las cadenas.

::: {#respuesta-16 .callout-note}
:::

### Pregunta 17

-   ¿Podrías decir que las muestras del modelo aproximado con Stan representan adecuadamente la distribución posterior de los parámetros del modelo? ¿En qué te basas para afirmar / refutar que es así?

::: {#respuesta-17 .callout-note}
:::

## Interpretación del modelo

### Pregunta 18

-   Compara los resultados de ajustar el modelo en Stan con los del modelo frecuentista en el objeto `out`. ¿Qué parámetro equivale a cada cuál, y cómo son los valores?

::: {#respuesta-18 .callout-note}
:::

### Pregunta 19

-   Utiliza el método `plot()` para representar el modelo Bayesiano aproximado con Stan e interprétalo. ¿Qué se está mostrando en esta representación?

*(NOTA: Este método devuelve un objeto de clase "ggplot", por lo que puedes usar cualquier función de `{ggplot2}` para dar formato y estilo a la salida gráfica si quieres.)*

::: {#respuesta-19 .callout-note}
:::

### Pregunta 20

-   El paquete [`{bayesplot}`](https://cran.r-project.org/package=bayesplot) proporciona gran variedad de funciones construidas sobre `{ggplot2}` para representar cadenas de Markov, distribuciones posteriores, etc. a partir de la salida de Stan. Revisa la ayuda del paquete y averigua cómo representar el "trazado" de las cadenas de Markov y las distribuciones posteriores de los parámetros e interpreta las salidas.

::: {#respuesta-20 .callout-note}
:::

## Salidas adicionales en Stan

La función `mcmc::metrop()` admite un argumento `outfun`, el cual es a su vez una función.
@geyer2011 [p. 33] utiliza este argumento para llamar a una función que admite un vector (argumento `z`, y devuelve ese mismo vector, pero añadiendo también sus valores al cuadrado).
De esta manera, además de los parámetros del modelo, la función `mcmc::metrop()` devuelve también esos mismos parámetros al cuadrado.

Fíjate en la sección [`generated quantities`](https://mc-stan.org/docs/reference-manual/blocks.html#program-block-generated-quantities) del [archivo con el modelo de Stan](src/geyer_2011_logistic.stan).

### Pregunta 21

-   Añade a la sección `generated quantities` del modelo en Stan el código necesario para que genere un valor real llamado `alpha_2`, con el valor al cuadrado de `alpha`, y un vector llamado `beta_2` con los valores al cuadrado de `beta`. Ayúdate de la [referencia de Stan sobre funciones reales](https://mc-stan.org/docs/functions-reference/real-valued_basic_functions.html). Después ejecuta el modelo en Stan de nuevo y comprueba si la salida ha generado los nuevos valores correctamente. Representa las distribuciones de estos nuevos valores.

::: {#respuesta-21 .callout-note}
:::

# Referencias
